{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twumasimb/miniconda3/envs/ingenious/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datasets\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import transformers\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed, broadcast_object_list\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizerFast,\n",
    "    BertForPreTraining,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorWithPadding,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    ")\n",
    "\n",
    "from selectionstrategies import SubmodStrategy\n",
    "from accelerate import InitProcessGroupKwargs\n",
    "from selectionstrategies.helper_fns import taylor_softmax_v1\n",
    "import numpy as np\n",
    "import pickle\n",
    "import faiss\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setup Parameters for args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self):\n",
    "        self.log_dir = \"./path/to/log_dir\"  # Update with your path\n",
    "        self.subset_dir = \"./path/to/subset_dir\"  # Update with your path\n",
    "        self.output_dir = \"./path/to/output_dir\"  # Update with your path\n",
    "        self.preprocessed = False  # Set to True if preprocessed\n",
    "        self.load_data_from_disk = None  # Set to True if loading data from disk\n",
    "        self.data_directory = None  # Update with your path if load_data_from_disk is True\n",
    "        self.dataset_name = None  # Specify dataset name if needed\n",
    "        self.dataset_config_name = None  # Specify dataset config name if needed\n",
    "        self.train_file = None  # Path to your training file if applicable\n",
    "        self.validation_file = None  # Path to your validation file if applicable\n",
    "        self.validation_split_percentage = 5  # Update this as per your requirement\n",
    "        self.pad_to_max_length = False  # Set to True to pad to max_length\n",
    "        self.model_name_or_path = None  # Update with your model name or path\n",
    "        self.config_name = None  # Specify config name or path if not the same as model_name\n",
    "        self.hidden_size = 768\n",
    "        self.num_hidden_layers = 12\n",
    "        self.num_attention_heads = 12\n",
    "        self.intermediate_size = 3072\n",
    "        self.tokenizer_name = None  # Specify tokenizer name or path if not the same as model_name\n",
    "        self.vocab_size = 30522\n",
    "        self.use_slow_tokenizer = False  # Set to True to use a slow tokenizer\n",
    "        self.per_device_train_batch_size = 8\n",
    "        self.per_device_eval_batch_size = 8\n",
    "        self.learning_rate = 1e-4\n",
    "        self.lr_max_steps = 1000000\n",
    "        self.weight_decay = 0.01\n",
    "        self.max_train_steps = 250000\n",
    "        self.gradient_accumulation_steps = 1\n",
    "        self.lr_scheduler_type = \"linear\"  # Adjust as needed, ensure it's a valid choice\n",
    "        self.num_warmup_steps = 10000\n",
    "        self.seed = None  # Specify a seed for reproducible training if needed\n",
    "        self.max_seq_length = 128\n",
    "        self.line_by_line = False  # Set to True if handling distinct lines as sequences\n",
    "        self.preprocessing_num_workers = 96\n",
    "        self.preprocess_batch_size = None  # Specify batch size during preprocessing if needed\n",
    "        self.overwrite_cache = False  # Set to True to overwrite cached sets\n",
    "        self.mlm_probability = 0.15\n",
    "        self.short_seq_prob = 0.1\n",
    "        self.nsp_probability = 0.5\n",
    "        self.subset_fraction = 0.25\n",
    "        self.selection_strategy = 'fl'  # Update with your strategy\n",
    "        self.optimizer = \"LazyGreedy\"  # Update with your optimizer\n",
    "        self.select_every = 25000\n",
    "        self.partition_strategy = \"random\"  # Update with your strategy\n",
    "        self.layer_for_similarity_computation = 9\n",
    "        self.num_partitions = 5000\n",
    "        self.parallel_processes = 96\n",
    "        self.num_warmstart_epochs = 10\n",
    "        self.checkpointing_steps = None  # Specify if needed\n",
    "        self.resume_from_checkpoint = None  # Specify path if resuming from checkpoint\n",
    "        self.temperature = 1.0  # Update if using a different temperature\n",
    "        self.main_process_port = None  # Update with your port\n",
    "        self.visible_gpus = '0'  # Update with your GPU(s)\n",
    "        self.init_split = None  # Specify to use a smaller portion of the data. Example: 20 means 80% of the data is used\n",
    "\n",
    "# Instantiate the args\n",
    "args = Args()\n",
    "\n",
    "\n",
    "now = datetime.datetime.now()\n",
    "timestamp = now.strftime(\"%d_%m_%Y_%H:%M:%S\")\n",
    "\n",
    "# The following can be modified as needed based on your requirements\n",
    "args.preprocessed = True\n",
    "args.visible_gpus = '1'  # Assuming you want to use the first GPU; adjust as needed\n",
    "args.main_process_port = 29500  # Example port; adjust as needed\n",
    "args.log_dir = f\"./output/logs/genious{timestamp}/\"\n",
    "args.model_dir = f\"./output/models/genious{timestamp}/\"\n",
    "args.subset_dir = f\"./output/subsets/genious{timestamp}/\"\n",
    "args.load_data_from_disk = None\n",
    "args.data_directory = \"./data\"\n",
    "args.tokenizer_name = \"bert-base-uncased\"\n",
    "args.preprocess_batch_size = 100\n",
    "args.per_device_train_batch_size = 4\n",
    "args.per_device_eval_batch_size = 4\n",
    "args.learning_rate = 1e-4\n",
    "args.lr_max_steps = 1000\n",
    "args.weight_decay = 0.01\n",
    "args.max_train_steps = 10\n",
    "args.gradient_accumulation_steps = 1\n",
    "args.num_warmup_steps = 10\n",
    "args.output_dir = args.model_dir\n",
    "args.model_type = \"bert\"\n",
    "args.max_seq_length = 64\n",
    "args.preprocessing_num_workers = 10\n",
    "args.mlm_probability = 0.15\n",
    "args.short_seq_prob = 0.1\n",
    "args.nsp_probability = 0.5\n",
    "args.subset_fraction = 0.25\n",
    "args.update_losses_every = 1250\n",
    "args.checkpointing_steps = 250 \n",
    "args.init_split = 95 # ignore 95% of the data\n",
    "args.dataset_name = \"bookcorpus\"\n",
    "\n",
    "\n",
    "# Set CUDA visible devices\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = args.visible_gpus\n",
    "\n",
    "debug = True\n",
    "\n",
    "# Create directories\n",
    "os.makedirs(args.log_dir, exist_ok=True)\n",
    "os.makedirs(args.model_dir, exist_ok=True)\n",
    "os.makedirs(args.subset_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Logger & Accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger=get_logger(__name__)\n",
    "init_process_group=InitProcessGroupKwargs(timeout=datetime.timedelta(seconds=75000))\n",
    "# Initialize the accelerator. We will let the accelerator handle device placement for us in this example.\n",
    "accelerator=Accelerator(kwargs_handlers=[init_process_group])\n",
    "# Make one log on every process with the configuration for debugging\n",
    "logging.basicConfig(\n",
    "    filename=os.path.join(args.log_dir,\"train_logs.log\"),\n",
    "    filemode=\"w\",\n",
    "    format=\"%(asctime)s - %(levelname)s - %(name)s - %(message)s\",\n",
    "    datefmt=\"%m/%d/%Y %H:%M:%S\",\n",
    "    level=logging.INFO,\n",
    ")\n",
    "logger.info(accelerator.state, main_process_only=False)\n",
    "\n",
    "# Setup logging, we only want one process per machine to log things on the screen.\n",
    "# accelerator.is_local_main_process is only True for one process per machine.\n",
    "# logger.setLevel(logging.INFO if accelerator.is_local_main_process else logging.ERROR)\n",
    "if accelerator.is_local_main_process:\n",
    "    datasets.utils.logging.set_verbosity_warning()\n",
    "    transformers.utils.logging.set_verbosity_info()\n",
    "else:\n",
    "    datasets.utils.logging.set_verbosity_error()\n",
    "    transformers.utils.logging.set_verbosity_error()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If passed along, set the training seed now.\n",
    "if args.seed is not None:\n",
    "    set_seed(args.seed)\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    if args.output_dir is not None:\n",
    "        os.makedirs(args.output_dir, exist_ok=True)\n",
    "accelerator.wait_for_everyone()\n",
    "if args.preprocessed == False:\n",
    "    logger.info(f\"Data is not preprocessed.\")\n",
    "    logger.info(f\"Loading the data.\")\n",
    "    if args.load_data_from_disk is not None:\n",
    "        if args.data_directory is not None:\n",
    "            raw_datasets=load_from_disk(args.data_directory)\n",
    "            if \"validation\" not in raw_datasets.keys():\n",
    "                raw_datasets=raw_datasets[\"train\"].train_test_split(test_size=(args.validation_split_percentage/100), shuffle=False)\n",
    "                raw_datasets=datasets.DatasetDict({\"train\": raw_datasets[\"train\"], \"validation\": raw_datasets[\"test\"]})\n",
    "    elif args.dataset_name is not None:\n",
    "        raw_datasets=load_dataset(args.dataset_name, args.dataset_config_name)\n",
    "        if \"validaton\" not in raw_datasets.keys() and args.init_split is not None:\n",
    "            raw_datasets=raw_datasets[\"train\"].train_test_split(test_size=(args.init_split/100), shuffle=False)\n",
    "            raw_datasets=raw_datasets[\"train\"].train_test_split(test_size=(args.validation_split_percentage/100), shuffle=False)\n",
    "            raw_datasets=datasets.DatasetDict({\"train\": raw_datasets[\"train\"], \"validation\": raw_datasets[\"test\"]})\n",
    "        elif \"validation\" not in raw_datasets.keys():\n",
    "            raw_datasets=raw_datasets.train_test_split(test_size=(args.validation_split_percentage/100), shuffle=False)\n",
    "            raw_datasets=datasets.DatasetDict({\"train\": raw_datasets[\"train\"], \"validation\": raw_datasets[\"test\"]})\n",
    "    else:\n",
    "        data_files={}\n",
    "        if args.train_file is not None:\n",
    "            data_files['train']=args.train_file\n",
    "        if args.validation_file is not None:\n",
    "            data_files['validation']=args.validation_file\n",
    "        extension=args.train_file.split(\".\")[-1]\n",
    "        if extension=='txt':\n",
    "            extension='text'\n",
    "        raw_datasets=load_dataset(extension, data_files=data_files)\n",
    "        if \"validation\" not in raw_datasets.keys():\n",
    "            raw_datasets=raw_datasets[\"train\"].train_test_split(test_size=(args.validation_split_percentage/100), shuffle=False)\n",
    "            raw_datasets=datasets.DatasetDict({\"train\": raw_datasets[\"train\"], \"validation\": raw_datasets[\"test\"]})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Configure Model and Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/vocab.txt from cache at /home/twumasimb/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer.json from cache at /home/twumasimb/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-uncased/resolve/main/tokenizer_config.json from cache at /home/twumasimb/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.76ea01b4b85ac16e2cec55c398cba7a943d89ab21dfdd973f6630a152e4b9aed\n",
      "loading configuration file https://huggingface.co/bert-base-uncased/resolve/main/config.json from cache at /home/twumasimb/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-uncased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.19.1\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 30522\n",
      "}\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load pretrained model and tokenizer\n",
    "#\n",
    "# In distributed training, the .from_pretrained methods guarantee that only one local process can concurrently\n",
    "# download model & vocab.\n",
    "logger.info(f\"Loading the model configuration.\")\n",
    "if args.config_name:\n",
    "    config=BertConfig.from_pretrained(args.config_name)\n",
    "elif args.model_name_or_path:\n",
    "    config=BertConfig.from_pretrained(args.model_name_or_path)\n",
    "else:\n",
    "    config=BertConfig(\n",
    "        vocab_size=args.vocab_size,\n",
    "        hidden_size=args.hidden_size,\n",
    "        num_hidden_layers=args.num_hidden_layers,\n",
    "        num_attention_heads=args.num_attention_heads,\n",
    "        intermediate_size=args.intermediate_size,\n",
    "        hidden_act=\"gelu\",\n",
    "        hidden_dropout_prob=0.1,\n",
    "        attention_probs_dropout_prob=0.1,\n",
    "        max_position_embeddings=512,\n",
    "        type_vocab_size=2,\n",
    "        initializer_range=0.02,\n",
    "        layer_norm_eps=1e-12,\n",
    "        position_embedding_type=\"absolute\",\n",
    "    )\n",
    "\n",
    "logger.info(f\"Loading the tokenizer.\")\n",
    "if args.tokenizer_name:\n",
    "    tokenizer=BertTokenizerFast.from_pretrained(args.tokenizer_name, use_fast=not args.use_slow_tokenizer)\n",
    "elif args.model_name_or_path:\n",
    "    tokenizer=BertTokenizerFast.from_pretrained(args.tokenizer_name, use_fast=not args.use_slow_tokenizer)\n",
    "else:\n",
    "    raise ValueError(\n",
    "        \"You are instantiating a new tokenizer from scratch. This is not supported by this script.\"\n",
    "        \"You can do it from another script, save it, and load it from here, using --tokenizer_name.\"\n",
    "    )\n",
    "\n",
    "logger.info(f\"Initializing Model.\")\n",
    "if args.model_name_or_path:\n",
    "    model=BertForPreTraining.from_pretrained(\n",
    "        args.model_name_or_path,\n",
    "        from_tf=bool(\".ckpt\"in args.model_name_or_path),\n",
    "        config=config\n",
    "    )\n",
    "else:\n",
    "    logger.info(\"Training a new model from scratch\")\n",
    "    model=BertForPreTraining(config)\n",
    "\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenizing all the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing the datasets\n",
    "#First we tokenize all the texts\n",
    "if args.preprocessed == False:\n",
    "    column_names=raw_datasets['train'].column_names\n",
    "    text_column_name=\"text\" if \"text\" in column_names else column_names[0]\n",
    "else:\n",
    "    column_names=[\"text\"]\n",
    "    text_column_name=\"text\"\n",
    "\n",
    "if args.max_seq_length is None:\n",
    "    max_seq_length=tokenizer.model_max_length\n",
    "    if max_seq_length>1024:\n",
    "        logger.warning(\n",
    "            f\"The tokenizer picked seems to have a very large `model_max_length` ({tokenizer.model_max_length}).\"\n",
    "            \"Picking 1024 instead. You can change the default value by passing --max_seq_length xxx\"\n",
    "        )\n",
    "        max_seq_length=1024\n",
    "else:\n",
    "    if args.max_seq_length>tokenizer.model_max_length:\n",
    "        logger.warning(\n",
    "            f\"The max_seq_length passed ({args.max_seq_length}) is larger than the maximum length for the \"\n",
    "            f\"model ({tokenizer.model_max_length}). Using max_seq_length={tokenizer.model_max_length}.\"\n",
    "        )\n",
    "    max_seq_length=min(args.max_seq_length, tokenizer.model_max_length)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Process the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main data processing function that will concatenate all texts from our dataset and generate chunks of \n",
    "#max_seq_length.\n",
    "\n",
    "def group_texts(examples, idx, split, tokenized_datasets):\n",
    "    # Account for [CLS], [SEP], [SEP]\n",
    "    max_num_tokens=max_seq_length-3\n",
    "    # We *usually* want to fill up the entire sequence since we are padding\n",
    "    # to `max_seq_length` anyways, so short sequences are generally wasted\n",
    "    # computation. However, we *sometimes*\n",
    "    # (i.e., short_seq_prob == 0.1 == 10% of the time) want to use shorter\n",
    "    # sequences to minimize the mismatch between pre-training and fine-tuning.\n",
    "    # The `target_seq_length` is just a rough target however, whereas\n",
    "    # `max_seq_length` is a hard limit.\n",
    "    target_seq_length=max_num_tokens\n",
    "    if random.random()<args.short_seq_prob:\n",
    "        target_seq_length=random.randint(2, max_num_tokens)\n",
    "    # We DON'T just concatenate all of the tokens from a document into a long\n",
    "    # sequence and choose an arbitrary split point because this would make the\n",
    "    # next sentence prediction task too easy. Instead, we split the input into\n",
    "    # segments \"A\" and \"B\" based on the actual \"sentences\" provided by the user\n",
    "    # input.\n",
    "    result={k: [] for k, v in tokenizer(\"\", return_special_tokens_mask=True).items()}\n",
    "    result['next_sentence_label']=[]\n",
    "    current_chunk=[]\n",
    "    current_length=0\n",
    "    i=0 \n",
    "    while i<len(idx):\n",
    "        segment={k: examples[k][i][1:-1] for k in examples.keys()}\n",
    "        current_chunk.append(segment)\n",
    "        current_length += len(segment['input_ids'])\n",
    "        if i==len(idx)-1 or current_length>=target_seq_length:\n",
    "            if current_chunk:\n",
    "                # `a_end` is how many segments from `current_chunk` go into the `A`\n",
    "                # (first) sentence.\n",
    "                a_end=1\n",
    "                if len(current_chunk)>=2:\n",
    "                    a_end=random.randint(1, len(current_chunk)-1)\n",
    "                tokens_a={k: [] for k, t in tokenizer(\"\", return_special_tokens_mask=True).items()}\n",
    "                for j in range(a_end):\n",
    "                    for k, v in current_chunk[j].items():\n",
    "                        tokens_a[k].extend(v)\n",
    "\n",
    "                tokens_b={k: [] for k, t in tokenizer(\"\", return_special_tokens_mask=True).items()}\n",
    "                # Random next\n",
    "                is_random_next=False\n",
    "                if len(current_chunk)==1 or random.random()<args.nsp_probability:\n",
    "                    is_random_next=True\n",
    "                    target_b_length=target_seq_length-len(tokens_a[\"input_ids\"])\n",
    "                    # This should rarely go for more than one iteration for large\n",
    "                    # corpora. However, just to be careful, we try to make sure that\n",
    "                    # the random document is not the same as the document\n",
    "                    # we're processing.\n",
    "                    for _ in range(10):\n",
    "                        random_segment_index=random.randint(0, len(tokenized_datasets[split])-len(idx)-1)\n",
    "                        if (random_segment_index-len(idx) not in idx) and (random_segment_index+len(idx) not in idx):\n",
    "                            break\n",
    "\n",
    "                    random_start=random.randint(0, len(idx)-1)\n",
    "                    for j in range(random_start, len(idx)):\n",
    "                        for k, v in {k: tokenized_datasets[split][random_segment_index+j][k][1:-1] for k in examples.keys()}.items():\n",
    "                            tokens_b[k].extend(v)\n",
    "                        if len(tokens_b['input_ids'])>=target_b_length:\n",
    "                            break\n",
    "                    # We didn't actually use these segments so we \"put them back\" so\n",
    "                    # they don't go to waste.\n",
    "                    num_unused_segments=len(current_chunk)-a_end\n",
    "                    i-=num_unused_segments\n",
    "                # Actual next\n",
    "                else:\n",
    "                    is_random_next=False\n",
    "                    for j in range(a_end, len(current_chunk)):\n",
    "                        for k, v in current_chunk[j].items():\n",
    "                            tokens_b[k].extend(v)\n",
    "\n",
    "                while True:\n",
    "                    total_length=len(tokens_a['input_ids'])+len(tokens_b['input_ids'])\n",
    "                    if total_length<=max_num_tokens:\n",
    "                        break\n",
    "                    trunc_tokens= tokens_a if len(tokens_a['input_ids'])>len(tokens_b['input_ids']) else tokens_b\n",
    "                    # We want to sometimes truncate from the front and sometimes from the\n",
    "                    # back to add more randomness and avoid biases.\n",
    "                    if random.random()<0.5:\n",
    "                        for k in trunc_tokens.keys():\n",
    "                            del trunc_tokens[k][0]\n",
    "                    else:\n",
    "                        for k in trunc_tokens.keys():\n",
    "                            trunc_tokens[k].pop()\n",
    "                inp={k: v[:-1] for k, v in tokenizer(\"\", return_special_tokens_mask=True).items()}\n",
    "                for k, v in tokens_a.items():\n",
    "                    inp[k].extend(v)\n",
    "                SEP={k: v[1:] for k, v in tokenizer(\"\", return_special_tokens_mask=True).items()}\n",
    "                for k, v in SEP.items():\n",
    "                    inp[k].extend(v)\n",
    "                tokens_b['token_type_ids']=list(map(lambda x: 1, tokens_b['token_type_ids']))\n",
    "                for k, v in SEP.items():\n",
    "                    tokens_b[k].extend(v)\n",
    "                tokens_b['token_type_ids'][-1]=1\n",
    "                for k, v in tokens_b.items():\n",
    "                    inp[k].extend(v)\n",
    "                inp['next_sentence_label']=int(is_random_next)\n",
    "                for k, v in inp.items():\n",
    "                    result[k].append(v)\n",
    "            current_chunk=[]\n",
    "            current_length=0\n",
    "        i+=1\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.preprocessed == False:\n",
    "    logger.info(f\"Beginning Tokenization.\")\n",
    "    if args.line_by_line == True:\n",
    "        #when using line_by_line, we just tokenize each non-empty line.\n",
    "        padding=\"max_length\" if args.pad_to_max_length==True else False\n",
    "\n",
    "        def tokenize_function(examples):\n",
    "            #remove empty lines\n",
    "            examples[text_column_name]=[\n",
    "                line for line in examples[text_column_name] if len(line)>0 and not line.isspace()\n",
    "            ]\n",
    "            return tokenizer(\n",
    "                examples[text_column_name],\n",
    "                padding=padding,\n",
    "                truncation=True,\n",
    "                max_length=max_seq_length,\n",
    "                #we use this option because DataCollatorForLanguageModeling (see below) is more efficient when it\n",
    "                #receives the `special_tokens_mask`\n",
    "                return_special_tokens_mask=True\n",
    "            )\n",
    "        \n",
    "        with accelerator.main_process_first():\n",
    "            tokenized_datasets=raw_datasets.map(\n",
    "                tokenize_function,\n",
    "                batched=True,\n",
    "                num_proc=args.preprocessing_num_workers,\n",
    "                remove_columns=[text_column_name],\n",
    "                load_from_cache_file=not args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on dataset line by line\",\n",
    "            )\n",
    "        train_dataset=tokenized_datasets[\"train\"]\n",
    "        eval_dataset=tokenized_datasets[\"validation\"]\n",
    "    else:\n",
    "        # otherwise, we tokenize every text, then concatenate them together before splitting them in smaller parts.\n",
    "        # We use `return_special_tokens=True` because DataCollatorForLanguageModeling (see below) is more efficient when it\n",
    "        # receives the `special_tokens_mask`.\n",
    "        def tokenize_function(examples):\n",
    "            return tokenizer(examples[text_column_name], return_special_tokens_mask=True)\n",
    "\n",
    "        with accelerator.main_process_first():\n",
    "            tokenized_datasets=raw_datasets.map(\n",
    "                tokenize_function,\n",
    "                batched=True,\n",
    "                num_proc=args.preprocessing_num_workers,\n",
    "                remove_columns=column_names,\n",
    "                load_from_cache_file=not args.overwrite_cache,\n",
    "                desc=\"Running tokenizer on every text in dataset\",\n",
    "            )\n",
    "        \n",
    "        # Note that with `batched=True`, this map processes 1000 texts together, so group_texts throws away a \n",
    "        # remainder for each of those groups of 1000 texts. You can adjust that batch_size here, but a higher value\n",
    "        # might be slower to preprocess.\n",
    "        #\n",
    "        # To speed up this part, we use multiprocessing. See the documentation of the map method for more information:\n",
    "        # https://huggingface.co/docs/datasets/package_reference/main_classes.html#datasets.Dataset.map\n",
    "        train_dataset=tokenized_datasets[\"train\"]\n",
    "        eval_dataset=tokenized_datasets[\"validation\"]\n",
    "        logger.info(f\"Grouping the tokenized dataset into chunks of {max_seq_length}.\")\n",
    "        with accelerator.main_process_first():\n",
    "            train_dataset=train_dataset.map(\n",
    "                group_texts,\n",
    "                fn_kwargs={'split': 'train', 'tokenized_datasets': tokenized_datasets},\n",
    "                batched=True,\n",
    "                batch_size=args.preprocess_batch_size,\n",
    "                num_proc=args.preprocessing_num_workers,\n",
    "                load_from_cache_file=not args.overwrite_cache,\n",
    "                with_indices=True,\n",
    "                desc=f\"Grouping Train texts in chunks of {max_seq_length}\",\n",
    "            )\n",
    "        with accelerator.main_process_first():\n",
    "            eval_dataset=eval_dataset.map(\n",
    "                group_texts,\n",
    "                fn_kwargs={'split': 'validation', 'tokenized_datasets': tokenized_datasets},\n",
    "                batched=True,\n",
    "                batch_size=args.preprocess_batch_size,\n",
    "                num_proc=args.preprocessing_num_workers,\n",
    "                load_from_cache_file=not args.overwrite_cache,\n",
    "                with_indices=True,\n",
    "                desc=f\"Grouping Validation texts in chunks of {max_seq_length}\",\n",
    "            )\n",
    "\n",
    "        prepared_data  = datasets.DatasetDict({\"train\": train_dataset, \"validation\": eval_dataset})\n",
    "        prepared_data.save_to_disk(\"./data/bookcorpus/bert/prepared\")\n",
    "        \n",
    "        dataset=prepared_data['train']\n",
    "        tokenizer=BertTokenizerFast.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "        def extract_first_sentences(examples):\n",
    "            for i, input_ids in enumerate(examples[\"input_ids\"]):\n",
    "                idx=input_ids.index(tokenizer.sep_token_id)\n",
    "                examples[\"input_ids\"][i]=input_ids[:idx+1]\n",
    "                examples[\"attention_mask\"][i]=examples[\"attention_mask\"][i][:idx+1]\n",
    "                examples[\"token_type_ids\"][i]=examples[\"token_type_ids\"][i][:idx+1]\n",
    "                examples[\"special_tokens_mask\"][i]=examples[\"special_tokens_mask\"][i][:idx+1]\n",
    "            return examples\n",
    "\n",
    "        # filter points from dataset with next_sentence_label == 0\n",
    "        with accelerator.main_process_first():\n",
    "            nsp_zero=dataset.filter(lambda examples: [x==0 for x in examples[\"next_sentence_label\"]], batched=True, num_proc=args.preprocessing_num_workers, keep_in_memory=True)\n",
    "            nsp_zero.save_to_disk(\"./data/bookcorpus/bert/nsp_zero\")\n",
    "                \n",
    "        # filter points from dataset with next_sentence_label == 1\n",
    "        with accelerator.main_process_first():\n",
    "                nsp_one=dataset.filter(lambda examples: [x==1 for x in examples[\"next_sentence_label\"]], batched=True, num_proc=args.preprocessing_num_workers, keep_in_memory=True)\n",
    "                nsp_one.save_to_disk(\"./data/bookcorpus/bert/nsp_one\")\n",
    "        \n",
    "        # extract first sentences from both datasets\n",
    "        with accelerator.main_process_first():\n",
    "            first_sent_nsp_zero=nsp_zero.map(extract_first_sentences, batched=True, num_proc=args.preprocessing_num_workers, remove_columns=[\"next_sentence_label\", \"special_tokens_mask\"], keep_in_memory=True)\n",
    "            first_sent_nsp_zero.save_to_disk(\"./data/bookcorpus/bert/first_sent_nsp_zero\")\n",
    "        with accelerator.main_process_first():\n",
    "            first_sent_nsp_one=nsp_one.map(extract_first_sentences, batched=True, num_proc=args.preprocessing_num_workers, remove_columns=[\"next_sentence_label\", \"special_tokens_mask\"], keep_in_memory=True)\n",
    "            first_sent_nsp_one.save_to_disk(\"./data/bookcorpus/bert/first_sent_nsp_one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If data is already preprocessed, load it them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "if args.preprocessed == True:\n",
    "    logger.info(f\"Loading preprocessed dataset(s) from disk.\")\n",
    "    dataset=load_from_disk(\"./data/bookcorpus/bert/prepared\")\n",
    "    train_dataset=dataset[\"train\"]\n",
    "    eval_dataset=dataset[\"validation\"]\n",
    "\n",
    "    nsp_zero=load_from_disk(\"./data/bookcorpus/bert/nsp_one\")\n",
    "    nsp_one=load_from_disk(\"./data/bookcorpus/bert/nsp_zero\")\n",
    "    first_sent_nsp_zero = load_from_disk(\"./data/bookcorpus/bert/first_sent_nsp_zero\")\n",
    "    first_sent_nsp_one = load_from_disk(\"./data/bookcorpus/bert/first_sent_nsp_one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initializing the random data subset selection process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initial Random Subset Selection\n",
    "if accelerator.is_main_process:\n",
    "    num_samples = int(round(len(train_dataset) * args.subset_fraction, 0))\n",
    "    init_subset_indices = [random.sample(list(range(len(train_dataset))), num_samples)]\n",
    "else:\n",
    "    init_subset_indices = [[]]\n",
    "accelerator.wait_for_everyone()\n",
    "broadcast_object_list(init_subset_indices)\n",
    "full_dataset=train_dataset\n",
    "subset_dataset = full_dataset.select(init_subset_indices[0])\n",
    "\n",
    "logger.info(f\"Full data has {len(full_dataset)} samples, subset data has {len(subset_dataset)} samples.\")\n",
    "# Conditional for small test subsets\n",
    "if len(train_dataset)>3:\n",
    "    # Log a few random samples from the training data\n",
    "    for index in random.sample(range(len(train_dataset)), 3):\n",
    "        logger.info(f\"Sample {index} of the training set: {train_dataset[index]}.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Collators and Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Collator\n",
    "# This one will take care of the randomly masking the tokens.\n",
    "data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=args.mlm_probability)\n",
    "data_collator_embd=DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "logger.info(f\"Creating Data Loaders\")\n",
    "# Dataloaders creation\n",
    "warmstart_dataloader=DataLoader(\n",
    "    train_dataset, shuffle=True, collate_fn=data_collator, batch_size=args.per_device_train_batch_size\n",
    ")\n",
    "\n",
    "first_sent_nsp_zero_dataloader=DataLoader(\n",
    "    first_sent_nsp_zero, shuffle=False, collate_fn=data_collator_embd, batch_size=args.per_device_eval_batch_size\n",
    ")\n",
    "first_sent_nsp_one_dataloader=DataLoader(\n",
    "    first_sent_nsp_one, shuffle=False, collate_fn=data_collator_embd, batch_size=args.per_device_eval_batch_size\n",
    ")\n",
    "\n",
    "subset_dataloader=DataLoader(\n",
    "    subset_dataset, shuffle=True, collate_fn=data_collator, batch_size=args.per_device_train_batch_size\n",
    ")\n",
    "\n",
    "eval_dataloader=DataLoader(\n",
    "    eval_dataset, collate_fn=data_collator, batch_size=args.per_device_eval_batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize Optimizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Intializing optimizer, learning rate schedule\")\n",
    "# Optimizer\n",
    "# Split weights in two groups, one with weight decay and the other not\n",
    "no_decay=[\"bias\", \"LayerNorm.weight\"]\n",
    "optimizer_grouped_parameters=[\n",
    "    {\n",
    "        \"params\":[p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\":args.weight_decay,\n",
    "    },\n",
    "    {\n",
    "        \"params\":[p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)],\n",
    "        \"weight_decay\": 0.0\n",
    "    }\n",
    "]\n",
    "\n",
    "optimizer=AdamW(optimizer_grouped_parameters, lr=args.learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Init for TPU & Init Scheduler "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On TPU, the tie weights in our model have been disconnected, so we need to restore the ties.\n",
    "if accelerator.distributed_type==DistributedType.TPU:\n",
    "    model.tie_weights()\n",
    "\n",
    "lr_scheduler=get_scheduler(\n",
    "    name=args.lr_scheduler_type,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=args.num_warmup_steps,\n",
    "    num_training_steps=args.lr_max_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the model for the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(f\"Prepare model, optimizer, warmstart_dataloader, first_sent_nsp_zero_dataloader, first_sent_nsp_one_dataloader, subset_dataloader, eval_dataloader with accelerate.\")\n",
    "# Prepare everything with our `accelerator`\n",
    "model, optimizer, warmstart_dataloader, first_sent_nsp_zero_dataloader, first_sent_nsp_one_dataloader, subset_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, warmstart_dataloader, first_sent_nsp_zero_dataloader, first_sent_nsp_one_dataloader, subset_dataloader, eval_dataloader)\n",
    "\n",
    "if args.selection_strategy in ['fl', 'logdet', 'gc', 'disparity-sum']:\n",
    "    subset_strategy = SubmodStrategy(logger, args.selection_strategy,\n",
    "                                num_partitions=args.num_partitions, partition_strategy=args.partition_strategy,\n",
    "                                optimizer=args.optimizer, similarity_criterion='feature', \n",
    "                                metric='cosine', eta=1, stopIfZeroGain=False, \n",
    "                                stopIfNegativeGain=False, verbose=False, lambdaVal=1)\n",
    "# Figure out how many steps we should save the Accelerator states\n",
    "if hasattr(args.checkpointing_steps, \"isdigit\"):\n",
    "    checkpointing_steps=args.checkpointing_steps\n",
    "    if args.checkpointing_steps.isdigit():\n",
    "        checkpointing_steps=int(args.checkpointing_steps)\n",
    "else:\n",
    "    checkpointing_steps=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Beginning Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Warmstarting the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "19it [31:40, 203.31s/it]                       "
     ]
    }
   ],
   "source": [
    "# Train!\n",
    "print(f\"Training on device: {accelerator.device}\")\n",
    "total_batch_size=args.per_device_train_batch_size * accelerator.num_processes * args.gradient_accumulation_steps\n",
    "main_start_time=time.time()\n",
    "logger.info(\"***** Running training *****\")\n",
    "logger.info(f\"  Num examples = {len(train_dataset)}\")\n",
    "logger.info(f\"  Num warm-start epochs = {args.num_warmstart_epochs}\")\n",
    "logger.info(f\"  Instantaneous batch size per device = {args.per_device_train_batch_size}\")\n",
    "logger.info(f\"  Total train batch size (w. parallel, distributed & accumulation) = {total_batch_size}\")\n",
    "logger.info(f\"  Gradient Accumulation steps = {args.gradient_accumulation_steps}\")\n",
    "logger.info(f\"  Total optimization steps = {args.max_train_steps}\")\n",
    "# Only show the progress bar once on each machine.\n",
    "progress_bar = tqdm(range(args.max_train_steps), disable=not accelerator.is_local_main_process)\n",
    "completed_steps = 0\n",
    "# Potentially load in the weights and states from a previous save\n",
    "if args.resume_from_checkpoint != None:\n",
    "    accelerator.print(f\"Resumed from checkpoint: {args.resume_from_checkpoint}\")\n",
    "    accelerator.load_state(args.resume_from_checkpoint)\n",
    "\n",
    "logger.info(f\"Begin the training.\")\n",
    "timing = []\n",
    "warmstart_start_time=time.time()\n",
    "for epoch in range(args.num_warmstart_epochs):\n",
    "    if epoch==0:\n",
    "        logger.info(\"Begin the warm-start\")\n",
    "    model.train()\n",
    "    for step, batch in enumerate(warmstart_dataloader):\n",
    "        start_time=time.time()\n",
    "        outputs=model(**batch)\n",
    "        loss=outputs.loss\n",
    "        logger.info(f\"Completed Steps: {1+completed_steps}; Loss: {loss.detach().float()}; lr: {lr_scheduler.get_last_lr()};\")\n",
    "        loss=loss/args.gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "        if step%args.gradient_accumulation_steps==0 or step==len(warmstart_dataloader)-1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            completed_steps+=1\n",
    "        if isinstance(checkpointing_steps, int):\n",
    "            if completed_steps%checkpointing_steps==0:\n",
    "                output_dir=f\"step_{completed_steps }\"\n",
    "                if args.output_dir is not None:\n",
    "                    output_dir=os.path.join(args.output_dir, output_dir)\n",
    "                accelerator.save_state(output_dir)\n",
    "        if completed_steps>=args.max_train_steps:\n",
    "            break\n",
    "        timing.append([(time.time() - start_time), 0])\n",
    "    \n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs=model(**batch)\n",
    "\n",
    "        loss=outputs.loss\n",
    "        losses.append(accelerator.gather(loss.repeat(args.per_device_eval_batch_size)))\n",
    "\n",
    "    losses=torch.cat(losses)\n",
    "    losses=losses[:len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity=math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity=float(\"inf\")\n",
    "\n",
    "    logger.info(f\"Steps {completed_steps}: perplexity: {perplexity}\")\n",
    "    if epoch==args.num_warmstart_epochs-1:\n",
    "        logger.info(\"End the warm-start\")\n",
    "# Save the state after warm-start\n",
    "output_dir=f\"after_warmstart_step_{completed_steps}\"\n",
    "if args.output_dir is not None:\n",
    "    output_dir=os.path.join(args.output_dir, output_dir)\n",
    "accelerator.save_state(output_dir)\n",
    "warmstart_end_time=time.time()\n",
    "logger.info(f\"Completed warm-start in {warmstart_end_time-warmstart_start_time} seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data subselection & Restructuring for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 90617/129050 [22:42<09:37, 66.49it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "104\n",
      "45\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[||||||||||||||||||||]100% [Iteration 103 of 103]eration 103 of 103]103]Iteration 101 of 103]\n",
      "[||||||||||||||||||||]100% [Iteration 103 of 103]Iteration 19103% of  [Iteration 20103 of ]103]\n",
      "[||||||||||||||||||||]100% [Iteration 103 of 103] [Iteration %45 [Iteration  of 101 of 103]103][Iteration 77 of 103]\n",
      "\n",
      "[|||||||||           ]49% [Iteration 51 of 103]3]3103]]n 48 of 103]103]103]\n",
      "[||||||||||||||||||||]100% [Iteration 103 of 103]% [Iteration  [Iteration 10179 of  of 103]103]\n",
      "[||||||||||||||||||||]100% [Iteration 103 of 103]103]\n",
      "[|                   ]8% [Iteration 9 of 103]\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "\u001b[A\n",
      "[|||||||             ]38% [Iteration 40 of 103]103]ration ]31 of 103]1% [Iteration 2 of ]103]n 2849 of  of 103103]]103]of ]11103 of ]103]\n",
      "[|||||||||||||       ]68% [Iterati   of ]67103%] [Iteration 70 of 103]03]]|||||||||||||||64% [Iteration 66 of  ]96% [Iteration 99103 of ]103]|||||||||||||||     ]75% [Iteration 78 of 103] % [Iteration 67 of 103]103]103% of 103103]]\n",
      "[|||||               ]25% [Iteration 26 of 103]3]03]on 101 of 103103]]of 34 of 103]103]03]103]\n",
      "[||||||||||||||||||||]100% [Iteration 103 of 103][Iteration %85 [Iteration  of 95 of 103]103]]3]Iteration 68 of 103]\n",
      "[                    ]1% [Iteration n 103 of 103]03]03]ion 37 of 103]103]n  of 94 of 103]103]]\n",
      "[||||||||||          ]51% [Iteration 53 of 103]3] 103103]]100 of 103]103]3]103]tion 72 of 103]3103]]n 7627 of ] of 103]103]103]103] of \n",
      " of |||||||||        ]62% [Iteration 64 of 103] of 103]ion 10387] of 103]n  of 86 of 103]103]] of % [Iteration 91 of 103]103]101 of 103]]16%\n",
      "[|||                 ]18% [Iteration           ]103]45% [Iteration 47 of 103][Iteration 10316 of %13] of 103 [Iteration 44 of % of 103 [Iteration 10342]] of 103]103]\n",
      "[103||||||||||||||||||]4% [Iteration 77 of 103]||||||||||||||||||||]100% [Iteration 103 of 103]103] of 61% [Iteration 63 of 103] of  of 103103]f 103  ]103]33% [Iteration 34 of of ]22103]% [Iteration 23 of 103]103 of 771103% of ]]103103]]% [Iteration %103]       %ation 10342] of  of ]103%29 [Iteration \n",
      "103 [103828% of ]]|103||||Iteration  [Iteration 33% of  [Iteration [29       75] of 8%103 [Iteration ion ] of ]103 of ]103f ]% [Iteration     71] of  of 03103]]3]n 2603] [Iteration ]1035043 of  of ]103103]]of 103103]]    ]48% [Iteration 50 of 103][Iteration 41 of 103][Iteration 83 of 103]f 83987103 of ||||10326%% of 103 [Iteration ]101]                 [Iteration ]27] of 21103]]103 of %]%103 [Iteration 103]22] [Iteration  of \n",
      "][%    ||||||||||| [Iteration ]         77]8158 of %% [Iteration  [Iteration 1038460 of ] of 103]10 10372]% [Iteration 75 of 103103]]tion ]60103 of 8221]103% of ] [Iteration 85 of 103]103] [Iteration 1] of 103]103103]] 73103 of eration  of ]]% of 103 of 75]%40 [Iteration 10324] [Iteration 84% of 103 of ] of  [Iteration 10378] of 103103]]of |||||||||          ]51% [Iteration 53\n",
      "\n",
      "[|||                 ]17% [Iteration 17 of 103]11 of 103]7 of 47%103 [Iteration ]49 of 103]  [Iteration 71 of 103] ]55% [Iteration 57 of 103]103]103] 90]%] [Iteration 10393289 of % of ] [Iteration 10392]5695 of  of 100 of %85]96]%85 [Iteration 103103% [Iteration of  of 103103\n",
      "\n",
      "[|||||||||           ]48% [Iteration 50 of 103]103]Iteration ]63 of 103]] 3710146 of 103]03]]]]eration  of 96 of 103]103]Iteration %]9066 [Iteration  of  of 102 of 103]103103]]of of 8 of ]] [Iteration 1 of  of 103on  of 65103 of 103]103]103]80 of  of % of  [Iteration 10319103103]103 of ]]]103\n",
      "\n",
      "[|||||||||||||       ]67% [Iteration 70 of 103]3]57% of  [Iteration 98103 of ]103]of 103]103]]on 556% of  of  [Iteration 91 of 103]103]103]]]]2615%% [Iteration  [Iteration 2716 of  of 103103]]           ]6% [Iteration 7 of 103]85103 of ]103] of 103]|                   ]6% [Iteration 7 of 103]\n",
      "[                    ]2% [Iteration 3 of 103]3]103]     ]]1% [Iteration 2 of on 101 of 103]103]3]]||||||||||       ]68% [Iteration 71 of 103]|||   ]88% [Iteration 91 of on 51 of 103]n 6 of 103]|||||||       ]65% [Iteration 67 of 103]%43 [Iteration %77 [Iteration  of 45 of 103]103]\n",
      "\n",
      "[||||||||||||||||||  ]91% [Iteration 94 of 103]f 103]ation 10365] of 103]]% [Iteration 58 of 103] [Iteration 16] of 103]103]0310333]] of 103]n 5 of 103]n 31 of 103]  ]72% [Iteration 75 of 103]\n",
      "\n",
      "[||||||||||||||      ]70% [Iteration 73 of 103]103]103] 67% [Iteration 10370]82 of  of 103]103]03]of 103]103]ion ]24] of 103]1032] of  103]]ation 52 of 103]tion 8 of |||           ]46% [Iteration 48 of 103]              ]3% [Iteration 1034] of 103]\n",
      "[|||||||||||         ]58% [Iteration 60 of 103]103]ration 18 of 103]103]of 103]103] of 103]3]3]3010336 of  of ]103103]]][Iteration 34 of 103]\n",
      "[||||||||||||||||||||]100% [Iteration 103 of 103]103teration 40103 of ]103] of 98 of 103]103]of 94 [Iteration  of 10337103 of ]]103]f ]103]Iteration  [Iteration % of ]103103 of 103]]eration  of 103]]        103 of 103 of 2410358]]103103]]]eration 53 of ||103]                  ]12% [Iteration 13 of 103] 103] [Iteration 76 of 103]        74] of %5]% [Iteration  [Iteration 776 of  of 103103]]\n",
      "\n",
      "[|||||||||||||||||   ]89% [Iteration 92 of 103]f 103]103]n           ]52% [Iteration 54 of 103] [Iteration 77 of 103]103]Iteration  of  of 67Iteration  of ]103 of 103]]70on %         ]]%10355 of ]103]] of 52 of 103873710317   of 103103]\n",
      "[|||||||||||         ]57% [Iteration 100 of 103]ration 60 of 103103]]103]f 103]103]%] [Iteration 90 of  [Iteration 4678 of  of 103]103]03]103]26]74 of 103103 of ]103]]103]f % of 103 [Iteration ]81103 of ]103]of 103103]103]]103]103103]]9 [Iteration ] of 14 of 103]\n",
      "\n",
      " [Iteration     ]58 of ]103]81% [Iteration 84 of 103]ration 16 of 103] of 103]||||||||||||||||||||]100% [Iteration 103 of 103]]]]70 of 103]96% [Iteration 99 of 103]103]|||||||||           ]of 103]f  of  of \n",
      "\n",
      "[|||||||||||         ]58% [Iteration 60 of 103]Iteration 2103 of ]3]3]teration 53103 of ]103]]on 94 of 103103103]]]teration 1034110392] of  of %f  of  %80 [Iteration  of ]%97 [Iteration  of  [Iteration 8285103075%73%26 [Iteration 91 of eration 1037266 of 103%97103 of ]103103]] of ]] [Iteration 103           [Iteration ]4652 of % [Iteration 10354 of \n",
      "\n",
      "[|||||||||||||||     ]77% [Iteration 80 of 103]103]Iteration  [Iteration 739 of  of 103]103]103]3]03103]]eration 2 of 10358] of 103]103]103]]03]on  of ]40103 of ]103] ]710332] of  of 103]103]ion ]99103] of  of ]103]103]ration  of 29103 of 103]]103]        %]103 [Iteration ]6030% of  [Iteration 62 of 103103]]\n",
      "%[ [Iteration |||||||||||||||||||34  of 331033%]% [Iteration  [Iteration 556 of  of 103]103]101 of 103103]]5103 of  of ]103103]] 10349]] of 103]]103]3%] [Iteration 10310343]03 of ] 69103 of ] of 103103]]|||]          23]% [Iteration 5324% of  [Iteration 10355] of \n",
      "\n",
      "[                    ]3% [Iteration 4 of 103]103] ]89                     of ]1% [Iteration 2 of 1% [Iteration 2 of 103]103]103]89 of ration 2 of 103]03]]103]29103]% [Iteration 30 of 103] 3 [Iteration 103103] of 5] of ]103]                 103]]]3168%||||]49      %] of 74 [Iteration %51 [Iteration  of 77103 of 103]]103]\n",
      " [Iteration [7|75 of %                   103]] [Iteration 878% of  [Iteration 9103  of 103                    103]]]2% [Iteration 3 of ]103]03]103]]103103]]103]]of 103]103103]]103]\n",
      "[17[ of |||||||                103      16]103] ]103]16% [Iteration 17 of 103] tion 16 of 103ration 10342103 of  of ]103103103]]]         ]48% [Iteration %%%] [Iteration 49 [Iteration  [Iteration  [Iteration 9013778 of  of 50% of  of 103 of 103 [Iteration  1% [Iteration 2 of 7% [Iteration 8 of 132% [Iteration %14 [Iteration  of 3 of 32% [Iteration %4 [Iteration  of 3 of 25% [Iteration 26 of 3% [Iteration 4 of 3% [Iteration 4 of 3% [Iteration 4 of                4 of 71% [Iteration 74 of ]26% [Iteration 27 of 6% [Iteration 7 of 6 of 9% [Iteration 10 of 512%% [Iteration  [Iteration 53 of 3 of 5% [Iteration 6 of 34 of 6% [Iteration 7 of |||||||||||  ]% [Iteration  of [||||||||||          ]                 ] of \n",
      "[|||||||||||||       ]67% [Iteration 70 of 103]103]3teration 30 of 103] [Iteration 23 of 103]]n 52 of  [Iteration 103]3%f 26 [Iteration 64 of %14 [Iteration 103 of 10366]103]] of           % [Iteration 40] of                     ]3% [Iteration 4 of  of 5                    ]% [Iteration 6                     of 4]% [Iteration 5 of 2% [Iteration 3 of ||||                ]24% [Iteration 25 of 103]\n",
      "\n",
      "[||||||||||          ]53% [Iteration 55 of 103]]eration 51 of 103]103]10% [Iteration 11 of              |||||[Iteration 8974]% [Iteration 1039223 of % [Iteration 24 of 103]103]on 45 of 87103 of  of ]103103]]103] 10310]103 of 33 of ] of 103103]103]]on 8595251032636 of  of eration 2 of 3097% [Iteration 8331 of % [Iteration 86 of 26 of % [Iteration 27 of 26% [Iteration 27 of 6783\n",
      "[10                  ]11% [Iteration 12 of 10354% [Iteration 56 of 98% [Iteration 101 of [103]||||||||||||||||||  ]91% [Iteration 94 of \n",
      "\n",
      "[|                   ]8% [Iteration 9 of 103]  ]]90 [Iteration 3]   ]||5% [Iteration 6 of                   ]10312]% [Iteration 13 of [Iteration %446 [Iteration ]464 of eration 2 of 21% [Iteration 22 of 2 of 27213 of % [Iteration 14% of  [Iteration 28 of 34% [Iteration 36 of 4 of 31 of 31%% [Iteration  [Iteration 2754 of 1 of % of  [Iteration 2 of 658%% [Iteration  [Iteration 760 of  of 1% [Iteration 2 of 2% [Iteration 3 of 1% [Iteration 2 of 1% [Iteration 2 of 19% [Iteration 20 of 30% [Iteration 31 of 2 of 11% [Iteration 2 of % [Iteration 2 of 12 of 1% [Iteration 2 of 1% [Iteration 2 of % [Iteration 7021 of %%5711 [Iteration  [Iteration 2% of  [Iteration 7359%% [Iteration  of  of  [Iteration 2 of 2 of 1% [Iteration 2 of \n",
      "\n",
      "[|||||||||||||||||   ]85% [Iteration 87 of 103]eration  [Iteration 3185 of  of 103]103]of 103103]]% [Iteration 30 of 103]03]]]] [Iteration 42 of 103]9 of 103]103]f  of  of ation ]238% of  [Iteration Iteration 66 of 103]"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "probs_nsp_zero=[]\n",
    "probs_nsp_one=[]\n",
    "greedyList_nsp_zero=[]\n",
    "greedyList_nsp_one=[]\n",
    "gains_nsp_zero=[]\n",
    "gains_nsp_one=[]\n",
    "\n",
    "if (args.num_warmstart_epochs!=0) or (args.resume_from_checkpoint != None):\n",
    "    logger.info(f\"Beginning the subset selection after warm-start or resuming from checkpoint\")\n",
    "    start_time=time.time()\n",
    "    if args.selection_strategy == 'Random-Online':\n",
    "        if accelerator.is_main_process:\n",
    "            subset_indices_nsp_zero = [random.sample(list(range(len(first_sent_nsp_zero))), math.floor(num_samples/2))]\n",
    "            subset_indices_nsp_one = [random.sample(list(range(len(first_sent_nsp_one))), math.ceil(num_samples/2))]\n",
    "        else:\n",
    "            subset_indices_nsp_zero = [[]]\n",
    "            subset_indices_nsp_one = [[]]\n",
    "    elif args.selection_strategy in [\"fl\", \"logdet\", \"gc\", \"disparity-min\"]:\n",
    "        logger.info(f\"Performing Subset selection for NSP class 0\")\n",
    "        pbar=tqdm(range(len(first_sent_nsp_zero_dataloader)), disable=not accelerator.is_local_main_process)\n",
    "        model.eval()\n",
    "        representations_nsp_zero=[]\n",
    "        batch_indices_nsp_zero=[]\n",
    "        total_cnt=0\n",
    "        total_storage=0\n",
    "\n",
    "        accelerator.wait_for_everyone()\n",
    "        unwrapped_model=accelerator.unwrap_model(model)\n",
    "        bert_model=unwrapped_model.bert\n",
    "        bert_model=accelerator.prepare(bert_model)\n",
    "        representations_start_time=time.time()\n",
    "        for step, batch in enumerate(first_sent_nsp_zero_dataloader):\n",
    "            with torch.no_grad():\n",
    "                output=bert_model(**batch, output_hidden_states=True)\n",
    "            embeddings=output[\"hidden_states\"][args.layer_for_similarity_computation]\n",
    "            mask=(batch['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float())\n",
    "            mask1=((batch['token_type_ids'].unsqueeze(-1).expand(embeddings.size()).float())==0)\n",
    "            mask=mask*mask1\n",
    "            mean_pooled=torch.sum(embeddings*mask, 1) / torch.clamp(mask.sum(1), min=1e-9)\n",
    "            mean_pooled = accelerator.gather(mean_pooled)\n",
    "            total_cnt += mean_pooled.size(0)\n",
    "            if accelerator.is_main_process:\n",
    "                mean_pooled = mean_pooled.cpu()\n",
    "                total_storage += sys.getsizeof(mean_pooled.storage())\n",
    "                representations_nsp_zero.append(mean_pooled)\n",
    "            pbar.update(1)\n",
    "        if accelerator.is_main_process:\n",
    "            representations_nsp_zero=torch.cat(representations_nsp_zero, dim=0)\n",
    "            representations_nsp_zero=representations_nsp_zero[:len(first_sent_nsp_zero)]\n",
    "            total_storage += sys.getsizeof(representations_nsp_zero.storage())\n",
    "            representations_nsp_zero=representations_nsp_zero.numpy()\n",
    "            logger.info('Representations(NSP Class 0) Size: {}, Total number of samples: {}'.format(total_storage/(1024 * 1024), total_cnt))\n",
    "            batch_indices_nsp_zero=list(range(len(first_sent_nsp_zero)))\n",
    "            logger.info('Length of indices: {}'.format(len(batch_indices_nsp_zero)))\n",
    "            logger.info('Representations(NSP Class 0) gathered. Shape of representations: {}. Length of indices: {}'.format(representations_nsp_zero.shape, len(batch_indices_nsp_zero)))\n",
    "        logger.info(f\"Representations(NSP Class 0) computed in {time.time()-representations_start_time} seconds\")\n",
    "        if accelerator.is_main_process:\n",
    "            partition_indices_nsp_zero, greedyIdx_nsp_zero, gains_nsp_zero = subset_strategy.select(len(batch_indices_nsp_zero)-1, batch_indices_nsp_zero, representations_nsp_zero, parallel_processes=args.parallel_processes, return_gains=True)\n",
    "            subset_indices_nsp_zero = [[]]\n",
    "            i=0\n",
    "            for p in gains_nsp_zero:\n",
    "                greedyList_nsp_zero.append(greedyIdx_nsp_zero[i:i+len(p)])         \n",
    "                i+=len(p)\n",
    "            probs_nsp_zero=[taylor_softmax_v1(torch.from_numpy(np.array([partition_gains])/args.temperature)).numpy()[0] for partition_gains in gains_nsp_zero]\n",
    "            rng=np.random.default_rng(args.seed+completed_steps)\n",
    "            for i, partition_prob in enumerate(probs_nsp_zero):\n",
    "                partition_budget=min(math.ceil((len(partition_prob)/len(batch_indices_nsp_zero)) * math.floor(num_samples/2)), len(partition_prob)-1)\n",
    "                subset_indices_nsp_zero[0].extend(rng.choice(greedyList_nsp_zero[i], size=partition_budget, replace=False, p=partition_prob).tolist())\n",
    "        else:\n",
    "            subset_indices_nsp_zero=[[]]\n",
    "    \n",
    "        logger.info(f\"Performing Subset selection for NSP class 1\")\n",
    "        pbar=tqdm(range(len(first_sent_nsp_one_dataloader)), disable=not accelerator.is_local_main_process)\n",
    "        model.eval()\n",
    "        representations_nsp_one=[]\n",
    "        batch_indices_nsp_one=[]\n",
    "        total_cnt=0\n",
    "        total_storage=0\n",
    "        representations_start_time=time.time()\n",
    "        for step, batch in enumerate(first_sent_nsp_one_dataloader):\n",
    "            with torch.no_grad():\n",
    "                output=bert_model(**batch, output_hidden_states=True)\n",
    "            embeddings=output[\"hidden_states\"][args.layer_for_similarity_computation]\n",
    "            mask=(batch['attention_mask'].unsqueeze(-1).expand(embeddings.size()).float())\n",
    "            mask1=((batch['token_type_ids'].unsqueeze(-1).expand(embeddings.size()).float())==0)\n",
    "            mask=mask*mask1\n",
    "            mean_pooled=torch.sum(embeddings*mask, 1) / torch.clamp(mask.sum(1), min=1e-9)\n",
    "            mean_pooled = accelerator.gather(mean_pooled)\n",
    "            total_cnt += mean_pooled.size(0)\n",
    "            if accelerator.is_main_process:\n",
    "                mean_pooled = mean_pooled.cpu()\n",
    "                total_storage += sys.getsizeof(mean_pooled.storage())\n",
    "                representations_nsp_one.append(mean_pooled)\n",
    "            pbar.update(1)\n",
    "        if accelerator.is_main_process:\n",
    "            representations_nsp_one=torch.cat(representations_nsp_one, dim=0)\n",
    "            representations_nsp_one=representations_nsp_one[:len(first_sent_nsp_one)]\n",
    "            total_storage += sys.getsizeof(representations_nsp_one.storage())\n",
    "            representations_nsp_one=representations_nsp_one.numpy()\n",
    "            logger.info('Representations(NSP Class 1) Size: {}, Total number of samples: {}'.format(total_storage/(1024 * 1024), total_cnt))\n",
    "            batch_indices_nsp_one=list(range(len(first_sent_nsp_one)))\n",
    "            logger.info('Length of indices: {}'.format(len(batch_indices_nsp_one)))\n",
    "            logger.info('Representations(NSP Class 1) gathered. Shape of representations: {}. Length of indices: {}'.format(representations_nsp_one.shape, len(batch_indices_nsp_one)))\n",
    "        logger.info(f\"Representations(NSP Class 1) computed in {time.time()-representations_start_time} seconds\")\n",
    "        if accelerator.is_main_process:\n",
    "            partition_indices_nsp_one, greedyIdx_nsp_one, gains_nsp_one = subset_strategy.select(len(batch_indices_nsp_one)-1, batch_indices_nsp_one, representations_nsp_one, parallel_processes=args.parallel_processes, return_gains=True)\n",
    "            subset_indices_nsp_one = [[]]\n",
    "            i=0\n",
    "            for p in gains_nsp_one:\n",
    "                greedyList_nsp_one.append(greedyIdx_nsp_one[i:i+len(p)])         \n",
    "                i+=len(p)\n",
    "            probs_nsp_one=[taylor_softmax_v1(torch.from_numpy(np.array([partition_gains])/args.temperature)).numpy()[0] for partition_gains in gains_nsp_one]\n",
    "            rng=np.random.default_rng(args.seed+completed_steps)\n",
    "            for i, partition_prob in enumerate(probs_nsp_one):\n",
    "                partition_budget=min(math.ceil((len(partition_prob)/len(batch_indices_nsp_one)) * math.ceil(num_samples/2)), len(partition_prob)-1)\n",
    "                subset_indices_nsp_one[0].extend(rng.choice(greedyList_nsp_one[i], size=partition_budget, replace=False, p=partition_prob).tolist())\n",
    "        else:\n",
    "            subset_indices_nsp_one=[[]]\n",
    "    accelerator.wait_for_everyone()    \n",
    "    broadcast_object_list(subset_indices_nsp_zero)\n",
    "    broadcast_object_list(subset_indices_nsp_one)\n",
    "    timing.append([0, time.time()-start_time])\n",
    "    logger.info(f\"First subset selection completed. Total Time taken(including embeddings computation): {time.time()-start_time}\")\n",
    "\n",
    "if accelerator.is_main_process:\n",
    "    output_file=f\"nsp_zero_subset_indices_after_step_{completed_steps}.pt\"\n",
    "    output_file=os.path.join(args.subset_dir, output_file)\n",
    "    torch.save(torch.tensor(subset_indices_nsp_zero), output_file)\n",
    "    output_file=f\"nsp_one_subset_indices_after_step_{completed_steps}.pt\"\n",
    "    output_file=os.path.join(args.subset_dir, output_file)\n",
    "    torch.save(torch.tensor(subset_indices_nsp_one), output_file)\n",
    "    output_file=f\"nsp_zero_gains_after_step_{completed_steps}.pkl\"\n",
    "    output_file=os.path.join(args.subset_dir, output_file)\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(gains_nsp_zero, f)\n",
    "    output_file=f\"nsp_one_gains_after_step_{completed_steps}.pkl\"\n",
    "    output_file=os.path.join(args.subset_dir, output_file)\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(gains_nsp_one, f)\n",
    "    output_file=f\"nsp_zero_partition_indices_after_step_{completed_steps}.pkl\"\n",
    "    output_file=os.path.join(args.subset_dir, output_file)\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(partition_indices_nsp_zero, f)\n",
    "    output_file=f\"nsp_one_partition_indices_after_step_{completed_steps}.pkl\"\n",
    "    output_file=os.path.join(args.subset_dir, output_file)\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(partition_indices_nsp_one, f)\n",
    "    output_file=f\"nsp_zero_greedy_indices_after_step_{completed_steps}.pkl\"\n",
    "    output_file=os.path.join(args.subset_dir, output_file)\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(greedyIdx_nsp_zero, f)\n",
    "    output_file=f\"nsp_one_greedy_indices_after_step_{completed_steps}.pkl\"\n",
    "    output_file=os.path.join(args.subset_dir, output_file)\n",
    "    with open(output_file, \"wb\") as f:\n",
    "        pickle.dump(greedyIdx_nsp_one, f)\n",
    "\n",
    "\n",
    "accelerator.wait_for_everyone()\n",
    "nsp_zero_subset_dataset=nsp_zero.select(subset_indices_nsp_zero[0])\n",
    "nsp_one_subset_dataset=nsp_one.select(subset_indices_nsp_one[0])\n",
    "# Concatenate the two datasets\n",
    "subset_dataset = concatenate_datasets([nsp_zero_subset_dataset, nsp_one_subset_dataset])\n",
    "subset_dataloader=DataLoader(\n",
    "    subset_dataset, shuffle=True, collate_fn=data_collator, batch_size=args.per_device_train_batch_size)\n",
    "subset_dataloader = accelerator.prepare(subset_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger.info(\"Begin the main training loop with importance re-sampling, after warm-start\")\n",
    "while completed_steps<args.max_train_steps:\n",
    "    model.train()\n",
    "    select_subset=False\n",
    "    for step, batch in enumerate(subset_dataloader):\n",
    "        train_time=0\n",
    "        subset_time=0\n",
    "        start_time=time.time()\n",
    "        outputs=model(**batch)\n",
    "        loss=outputs.loss\n",
    "        logger.info(f\"Completed Steps: {1+completed_steps}; Loss: {loss.detach().float()}; lr: {lr_scheduler.get_last_lr()};\")\n",
    "        loss=loss/args.gradient_accumulation_steps\n",
    "        accelerator.backward(loss)\n",
    "        if step%args.gradient_accumulation_steps==0 or step==len(subset_dataloader)-1:\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "            completed_steps+=1\n",
    "        train_time += (time.time() - start_time)\n",
    "\n",
    "        if isinstance(checkpointing_steps, int):\n",
    "            if completed_steps%checkpointing_steps==0:\n",
    "                output_dir=f\"step_{completed_steps }\"\n",
    "                if args.output_dir is not None:\n",
    "                    output_dir=os.path.join(args.output_dir, output_dir)\n",
    "                accelerator.save_state(output_dir)\n",
    "\n",
    "        if completed_steps>=args.max_train_steps:\n",
    "            break\n",
    "        \n",
    "        if (completed_steps)%args.select_every==0:\n",
    "            select_subset=True\n",
    "            break\n",
    "        timing.append([train_time, subset_time])\n",
    "    if select_subset==True:\n",
    "        accelerator.wait_for_everyone()\n",
    "        start_time = time.time()\n",
    "        num_samples = int(round(len(full_dataset) * args.subset_fraction, 0)) \n",
    "        if args.selection_strategy == 'Random-Online':\n",
    "            if accelerator.is_main_process:\n",
    "                subset_indices_nsp_zero = [random.sample(list(range(len(first_sent_nsp_zero))), math.floor(num_samples/2))]\n",
    "                subset_indices_nsp_one = [random.sample(list(range(len(first_sent_nsp_one))), math.ceil(num_samples/2))]\n",
    "            else:\n",
    "                subset_indices_nsp_zero = [[]]\n",
    "                subset_indices_nsp_one = [[]]\n",
    "        elif args.selection_strategy in [\"fl\", \"logdet\", \"gc\", \"disparity-min\"]:\n",
    "            logger.info(f\"Performing Subset selection for NSP class 0\")\n",
    "            sampling_start_time=time.time()\n",
    "            if accelerator.is_main_process:\n",
    "                subset_indices_nsp_zero=[[]]\n",
    "                rng=np.random.default_rng(args.seed+completed_steps)\n",
    "                for i, partition_prob in enumerate(probs_nsp_zero):\n",
    "                    partition_budget=min(math.ceil((len(partition_prob)/len(batch_indices_nsp_zero)) * math.floor(num_samples/2)), len(partition_prob)-1)\n",
    "                    subset_indices_nsp_zero[0].extend(rng.choice(greedyList_nsp_zero[i], size=partition_budget, replace=False, p=partition_prob).tolist())\n",
    "            else:\n",
    "                subset_indices_nsp_zero=[[]]\n",
    "            logger.info(\"Sampling time(NSP Class 0): {}\".format(time.time()-sampling_start_time))\n",
    "        \n",
    "            logger.info(f\"Performing Subset selection for NSP class 1\")\n",
    "            sampling_start_time=time.time()\n",
    "            if accelerator.is_main_process:\n",
    "                subset_indices_nsp_one=[[]]\n",
    "                rng=np.random.default_rng(args.seed+completed_steps)\n",
    "                for i, partition_prob in enumerate(probs_nsp_one):\n",
    "                    partition_budget=min(math.ceil((len(partition_prob)/len(batch_indices_nsp_one)) * math.ceil(num_samples/2)), len(partition_prob)-1)\n",
    "                    subset_indices_nsp_one[0].extend(rng.choice(greedyList_nsp_one[i], size=partition_budget, replace=False, p=partition_prob).tolist())\n",
    "            else:\n",
    "                subset_indices_nsp_one=[[]]\n",
    "            logger.info(\"Sampling time(NSP Class 1): {}\".format(time.time()-sampling_start_time))\n",
    "        accelerator.wait_for_everyone()\n",
    "        broadcast_object_list(subset_indices_nsp_zero)\n",
    "        broadcast_object_list(subset_indices_nsp_one)\n",
    "        timing.append([0, time.time()-start_time])\n",
    "        if accelerator.is_main_process:\n",
    "            output_file=f\"nsp_zero_subset_indices_after_step_{completed_steps}.pt\"\n",
    "            output_file=os.path.join(args.subset_dir, output_file)\n",
    "            torch.save(torch.tensor(subset_indices_nsp_zero), output_file)\n",
    "            output_file=f\"nsp_one_subset_indices_after_step_{completed_steps}.pt\"\n",
    "            output_file=os.path.join(args.subset_dir, output_file)\n",
    "            torch.save(torch.tensor(subset_indices_nsp_one), output_file)\n",
    "        accelerator.wait_for_everyone()\n",
    "\n",
    "        nsp_zero_subset_dataset=nsp_zero.select(subset_indices_nsp_zero[0])\n",
    "        nsp_one_subset_dataset=nsp_one.select(subset_indices_nsp_one[0])\n",
    "        # Concatenate the two datasets\n",
    "        subset_dataset = concatenate_datasets([nsp_zero_subset_dataset, nsp_one_subset_dataset])\n",
    "        subset_dataloader=DataLoader(\n",
    "            subset_dataset, shuffle=True, collate_fn=data_collator, batch_size=args.per_device_train_batch_size)\n",
    "        subset_dataloader = accelerator.prepare(subset_dataloader)\n",
    "\n",
    "        subset_time=time.time()-start_time\n",
    "        select_subset=False\n",
    "        timing.append([0, subset_time])\n",
    "        logger.info(f\"Subset selection time(total resampling time): {time.time()-start_time} seconds.\")\n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.no_grad():\n",
    "            outputs=model(**batch)\n",
    "\n",
    "        loss=outputs.loss\n",
    "        losses.append(accelerator.gather(loss.repeat(args.per_device_eval_batch_size)))\n",
    "\n",
    "    losses=torch.cat(losses)\n",
    "    losses=losses[:len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity=math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity=float(\"inf\")\n",
    "\n",
    "    logger.info(f\"Steps {completed_steps}: perplexity: {perplexity}\")\n",
    "\n",
    "logger.info(f\"Timing: {timing}\")\n",
    "logger.info(f\"Saving the final model after {completed_steps} steps.\")\n",
    "if args.output_dir is not None:\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model=accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(\n",
    "        args.output_dir, is_main_process=accelerator.is_main_process, save_function=accelerator.save\n",
    "    )\n",
    "    if accelerator.is_main_process:\n",
    "        tokenizer.save_pretrained(args.output_dir)\n",
    "logger.info(f\"Training completed successfully in {time.time()-main_start_time} seconds.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "genious",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "undefined.undefined.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
