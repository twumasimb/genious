{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary libraries\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datasets\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import transformers\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed, broadcast_object_list\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizerFast,\n",
    "    BertForPreTraining,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorWithPadding,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    ")\n",
    "# from transformers.utils.versions import require_version\n",
    "# from selectionstrategies import SubmodStrategy\n",
    "# from accelerate import InitProcessGroupKwargs\n",
    "# from selectionstrategies.helper_fns import taylor_softmax_v1\n",
    "# import numpy as np\n",
    "import pickle\n",
    "# import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "dataset_name = \"Salesforce/wikitext\"\n",
    "dataset_config_name = \"wikitext-2-raw-v1\"\n",
    "validation_split_percentage = 80\n",
    "model_config_name = \"google-bert/bert-base-uncased\"\n",
    "tokenizer_name = \"bert-base-uncased\"\n",
    "use_slow_tokenizer = False  # Bool\n",
    "num_workers = None # (int)\n",
    "max_seq_len = None\n",
    "short_seq_prob = None\n",
    "nsp_probability = None\n",
    "batch_size = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading readme: 100%|██████████| 10.5k/10.5k [00:00<00:00, 32.1MB/s]\n",
      "Downloading data: 100%|██████████| 733k/733k [00:00<00:00, 2.41MB/s]\n",
      "Downloading data: 100%|██████████| 6.36M/6.36M [00:00<00:00, 25.7MB/s]\n",
      "Downloading data: 100%|██████████| 657k/657k [00:00<00:00, 6.59MB/s]\n",
      "Generating test split: 100%|██████████| 4358/4358 [00:00<00:00, 136318.24 examples/s]\n",
      "Generating train split: 100%|██████████| 36718/36718 [00:00<00:00, 1084613.60 examples/s]\n",
      "Generating validation split: 100%|██████████| 3760/3760 [00:00<00:00, 844656.58 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Get and Preprocess the dataset for the task.\n",
    "raw_datasets = load_dataset(\"Salesforce/wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "if 'validation' not in raw_datasets.keys():\n",
    "    raw_datasets=raw_datasets[\"train\"].train_test_split(test_size=(validation_split_percentage/100), shuffle=False)\n",
    "    raw_datasets=datasets.DatasetDict({\"train\": raw_datasets[\"train\"], \"validation\": raw_datasets[\"test\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/torch/lib/python3.12/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and instance of the model along with its tokenizer\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(tokenizer_name, use_fast= not use_slow_tokenizer)\n",
    "\n",
    "# Load the model\n",
    "config = BertConfig.from_pretrained(model_config_name)\n",
    "\n",
    "# Instantiating the model\n",
    "model = BertForPreTraining(config)\n",
    "\n",
    "# Resizing the token embeddings to fit the tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running tokenizer on every text in dataset:   0%|          | 0/4358 [00:00<?, ? examples/s]Token indices sequence length is longer than the specified maximum sequence length for this model (525 > 512). Running this sequence through the model will result in indexing errors\n",
      "Running tokenizer on every text in dataset: 100%|██████████| 4358/4358 [00:00<00:00, 33145.97 examples/s]\n",
      "Running tokenizer on every text in dataset: 100%|██████████| 36718/36718 [00:01<00:00, 21929.23 examples/s]\n",
      "Running tokenizer on every text in dataset: 100%|██████████| 3760/3760 [00:00<00:00, 31723.77 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenize and group the data based on the kind of model\n",
    "\n",
    "column_names=raw_datasets['train'].column_names\n",
    "text_column_name=\"text\" if \"text\" in column_names else column_names[0]\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[text_column_name])\n",
    "\n",
    "tokenized_dataset = raw_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=num_workers, \n",
    "    remove_columns=column_names,\n",
    "    desc=\"Running tokenizer on every text in dataset\"\n",
    ")\n",
    "\n",
    "# Grouping the data \n",
    "from experiment_utils import group_texts\n",
    "\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "eval_dataset = tokenized_dataset[\"validation\"]\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    group_texts, \n",
    "    fn_kwargs={'split': 'train', 'tokenizer':tokenizer, 'max_seq_length': max_seq_len, \n",
    "               'short_seq_prob':short_seq_prob, 'nsp_probability':nsp_probability, 'tokenized_datasets':tokenized_dataset},\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=num_workers,\n",
    "    with_indices=True,\n",
    "    desc=f\"Grouping Train texts into chucks of {max_seq_len}\"\n",
    ")\n",
    "\n",
    "eval_dataset = eval_dataset.map(\n",
    "    group_texts, \n",
    "    fn_kwargs={'split': 'Validation', 'tokenizer':tokenizer, 'max_seq_length': max_seq_len, \n",
    "               'short_seq_prob':short_seq_prob, 'nsp_probability':nsp_probability, 'tokenized_datasets':tokenized_dataset},\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=num_workers,\n",
    "    with_indices=True,\n",
    "    desc=f\"Grouping Validation texts into chucks of {max_seq_len}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datacollators and dataloaders \n",
    "\n",
    "# warmstart dataloader\n",
    "\n",
    "# first sent nsp zero dataloader\n",
    "\n",
    "# first sent nsp one  dataloader\n",
    "\n",
    "# subset dataloader (train)\n",
    "\n",
    "# eval dataloader (validation & testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model and training instance\n",
    "\n",
    "# Optimizer\n",
    "\n",
    "# learning scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Warmstart the model: Train the model with the warmstart data for warmstart epochs\n",
    "\n",
    "# Plot both training & perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define subset selection strategies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Begin subset selection \n",
    "\n",
    "# Choose a selection strategy\n",
    "\n",
    "# Unwrap the model and set it in evaluation mode.\n",
    "\n",
    "# Go through the model specific dataset\n",
    "\n",
    "# Get the embedding and save them in a list.\n",
    "\n",
    "# Using the list and the selection strategy, get the indices and the gains of each data point in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the data into a dataset called subset_dataset\n",
    "\n",
    "# add the data to the subset dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with importance re-sampling\n",
    "\n",
    "# Train on the entire dataset once\n",
    "\n",
    "# Sample using the indices and gains\n",
    "\n",
    "# Train the model on the sampled dataset\n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "# Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal Addition: Inference on the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ingenious",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
