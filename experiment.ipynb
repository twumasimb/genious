{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/twumasimb/miniconda3/envs/torch/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2024-07-31 16:48:41.615966: I tensorflow/core/util/port.cc:113] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 16:48:41.755495: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:479] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 16:48:41.828297: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:10575] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 16:48:41.828452: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1442] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 16:48:41.936396: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 16:48:44.070809: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# import the necessary libraries\n",
    "import argparse\n",
    "import datetime\n",
    "import time\n",
    "import logging\n",
    "import math\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import datasets\n",
    "import torch\n",
    "from torch.optim import AdamW\n",
    "from datasets import load_dataset, load_from_disk, concatenate_datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm.auto import tqdm\n",
    "import transformers\n",
    "from accelerate import Accelerator, DistributedType\n",
    "from accelerate.logging import get_logger\n",
    "from accelerate.utils import set_seed, broadcast_object_list\n",
    "from transformers import (\n",
    "    BertConfig,\n",
    "    BertTokenizerFast,\n",
    "    BertForPreTraining,\n",
    "    DataCollatorForLanguageModeling,\n",
    "    DataCollatorWithPadding,\n",
    "    SchedulerType,\n",
    "    get_scheduler,\n",
    ")\n",
    "from transformers.utils.versions import require_version\n",
    "from selectionstrategies import SubmodStrategy\n",
    "from accelerate import InitProcessGroupKwargs\n",
    "from selectionstrategies.helper_fns import taylor_softmax_v1\n",
    "import numpy as np\n",
    "import pickle\n",
    "import faiss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Create a logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Set the logging level\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Create a file handler\n",
    "file_handler = logging.FileHandler('logfile.log')\n",
    "\n",
    "# Create a formatter\n",
    "formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# Set the formatter for the file handler\n",
    "file_handler.setFormatter(formatter)\n",
    "\n",
    "# Add the file handler to the logger\n",
    "logger.addHandler(file_handler)\n",
    "\n",
    "# Log a message\n",
    "logger.info('Logger created')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Variables \n",
    "dataset_name = \"Salesforce/wikitext\"\n",
    "dataset_config_name = \"wikitext-2-raw-v1\"\n",
    "validation_split_percentage = 80\n",
    "model_config_name = \"google-bert/bert-base-uncased\"\n",
    "tokenizer_name = \"bert-base-uncased\"\n",
    "use_slow_tokenizer = False  # Bool\n",
    "num_workers = None # (int)\n",
    "max_seq_len = 128\n",
    "short_seq_prob = 0.1\n",
    "nsp_probability = 0.1\n",
    "batch_size = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get and Preprocess the dataset for the task.\n",
    "raw_datasets = load_dataset(\"Salesforce/wikitext\", \"wikitext-2-raw-v1\")\n",
    "\n",
    "if 'validation' not in raw_datasets.keys():\n",
    "    raw_datasets=raw_datasets[\"train\"].train_test_split(test_size=(validation_split_percentage/100), shuffle=False)\n",
    "    raw_datasets=datasets.DatasetDict({\"train\": raw_datasets[\"train\"], \"validation\": raw_datasets[\"test\"]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4358\n",
       "    })\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 36718\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 3760\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Uncomment to use custom config\n",
    "\n",
    "# config = BertConfig(\n",
    "#     vocab_size=vocab_size,\n",
    "#     hidden_size=hidden_size,\n",
    "#     num_hidden_layers=num_hidden_layers,\n",
    "#     num_attention_heads=num_attention_heads,\n",
    "#     intermediate_size=intermediate_size,\n",
    "#     hidden_act=\"gelu\",\n",
    "#     hidden_dropout_prob=0.1,\n",
    "#     attention_probs_dropout_prob=0.1,\n",
    "#     max_position_embeddings=512,\n",
    "#     type_vocab_size=2,\n",
    "#     initializer_range=0.02,\n",
    "#     layer_norm_eps=1e-12,\n",
    "#     position_embedding_type=\"absolute\",\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Embedding(30522, 768, padding_idx=0)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create and instance of the model along with its tokenizer\n",
    "\n",
    "# Tokenizer\n",
    "tokenizer = BertTokenizerFast.from_pretrained(tokenizer_name, use_fast= not use_slow_tokenizer)\n",
    "\n",
    "# Load the model\n",
    "config = BertConfig.from_pretrained(model_config_name)\n",
    "\n",
    "# Instantiating the model\n",
    "model = BertForPreTraining(config)\n",
    "\n",
    "# Resizing the token embeddings to fit the tokenizer\n",
    "model.resize_token_embeddings(len(tokenizer))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize and group the data based on the kind of model\n",
    "\n",
    "column_names=raw_datasets['train'].column_names\n",
    "text_column_name=\"text\" if \"text\" in column_names else column_names[0]\n",
    "\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[text_column_name])\n",
    "\n",
    "tokenized_dataset = raw_datasets.map(\n",
    "    tokenize_function,\n",
    "    batched=True,\n",
    "    num_proc=num_workers, \n",
    "    remove_columns=column_names,\n",
    "    desc=\"Running tokenizer on every text in dataset\"\n",
    ")\n",
    "\n",
    "# Grouping the data \n",
    "from experiment_utils import group_texts\n",
    "\n",
    "train_dataset = tokenized_dataset[\"train\"]\n",
    "eval_dataset = tokenized_dataset[\"validation\"]\n",
    "\n",
    "train_dataset = train_dataset.map(\n",
    "    group_texts, \n",
    "    fn_kwargs={'split': 'train', 'tokenizer':tokenizer, 'max_seq_length': max_seq_len, \n",
    "               'short_seq_prob':short_seq_prob, 'nsp_probability':nsp_probability, 'tokenized_datasets':tokenized_dataset},\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=num_workers,\n",
    "    with_indices=True,\n",
    "    desc=f\"Grouping Train texts into chucks of {max_seq_len}\"\n",
    ")\n",
    "\n",
    "eval_dataset = eval_dataset.map(\n",
    "    group_texts, \n",
    "    fn_kwargs={'split': 'validation', 'tokenizer':tokenizer, 'max_seq_length': max_seq_len, \n",
    "               'short_seq_prob':short_seq_prob, 'nsp_probability':nsp_probability, 'tokenized_datasets':tokenized_dataset},\n",
    "    batched=True,\n",
    "    batch_size=batch_size,\n",
    "    num_proc=num_workers,\n",
    "    with_indices=True,\n",
    "    desc=f\"Grouping Validation texts into chucks of {max_seq_len}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'next_sentence_label'],\n",
       "    num_rows: 1195\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[CLS] pots, although lines baited with octopus or cuttlefish sometimes succeed in tempting them out, to allow them to be caught in a net or by hand. in 2008, 4 @, @ 386 t of h. gammarus were caught across europe and north africa, of which 3 @, @ 462 t ( 79 % ) was caught in the british isles ( including the channel islands ). the minimum landing size for h. gammarus is a carapace length of 87 mm ( 3 @. @ 4 in [SEP] aquaculture systems for h. gammarus are under development, and production rates are still very low. [SEP]'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(eval_dataset[9]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Filter: 100%|██████████| 11789/11789 [00:00<00:00, 532296.83 examples/s]\n",
      "Filter: 100%|██████████| 11789/11789 [00:00<00:00, 1277394.14 examples/s]\n",
      "Map: 100%|██████████| 6555/6555 [00:00<00:00, 6778.78 examples/s]\n",
      "Map: 100%|██████████| 5234/5234 [00:00<00:00, 6378.93 examples/s]\n"
     ]
    }
   ],
   "source": [
    "# Prepare the data\n",
    "prepared_data = datasets.DatasetDict({\"train\": train_dataset, \"validation\": eval_dataset})\n",
    "dataset=prepared_data['train']\n",
    "\n",
    "def extract_first_sentences(examples):\n",
    "    for i, input_ids in enumerate(examples[\"input_ids\"]):\n",
    "        idx=input_ids.index(tokenizer.sep_token_id)\n",
    "        examples[\"input_ids\"][i]=input_ids[:idx+1]\n",
    "        examples[\"attention_mask\"][i]=examples[\"attention_mask\"][i][:idx+1]\n",
    "        examples[\"token_type_ids\"][i]=examples[\"token_type_ids\"][i][:idx+1]\n",
    "        examples[\"special_tokens_mask\"][i]=examples[\"special_tokens_mask\"][i][:idx+1]\n",
    "    return examples\n",
    "\n",
    "# Separate the data into those that have the next sentence labels and those that do not.\n",
    "nsp_zero=dataset.filter(lambda examples: [x==0 for x in examples[\"next_sentence_label\"]], batched=True, num_proc=num_workers, keep_in_memory=True)\n",
    "nsp_one=dataset.filter(lambda examples: [x==1 for x in examples[\"next_sentence_label\"]], batched=True, num_proc=num_workers, keep_in_memory=True)\n",
    "\n",
    "# Extract the first sentences from both datasets\n",
    "first_sent_nsp_zero=nsp_zero.map(extract_first_sentences, batched=True, num_proc=num_workers, remove_columns=[\"next_sentence_label\", \"special_tokens_mask\"], keep_in_memory=True)\n",
    "first_sent_nsp_one=nsp_one.map(extract_first_sentences, batched=True, num_proc=num_workers, remove_columns=[\"next_sentence_label\", \"special_tokens_mask\"], keep_in_memory=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"[CLS] 2010, carrying over a large portion of the work done on valkyria chronicles ii. while it retained the standard features of the series, it also underwent multiple adjustments, such as making the game more forgiving for series newcomers. character designer raita honjou and composer hitoshi sakimoto both returned from previous entries, along with valkyria chronicles ii director takeshi ozawa. a large team of writers handled the script. the game's opening theme was sung [SEP]\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(first_sent_nsp_one[0]['input_ids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset_fraction = 0.25\n",
    "\n",
    "# Sample a subset of the train dataset\n",
    "num_samples = int(round(len(train_dataset) * subset_fraction, 0))\n",
    "init_subset_indices = [random.sample(list(range(len(train_dataset))), num_samples)]\n",
    "full_dataset=train_dataset\n",
    "subset_dataset = full_dataset.select(init_subset_indices[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask'],\n",
       "    num_rows: 6555\n",
       "})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "first_sent_nsp_zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'next_sentence_label'],\n",
       "    num_rows: 11789\n",
       "})"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'token_type_ids', 'attention_mask', 'special_tokens_mask', 'next_sentence_label'],\n",
       "    num_rows: 2947\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subset_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlm_probability = 0.15\n",
    "train_batch_size = 4\n",
    "eval_batch_size = 4\n",
    "\n",
    "# Create datacollators\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm_probability=mlm_probability)\n",
    "data_collator_embd = DataCollatorWithPadding(tokenizer=tokenizer)\n",
    "\n",
    "# warmstart dataloader (train on all the train dataset during warmup)\n",
    "warmstart_dataloader = DataLoader(train_dataset.remove_columns(['special_tokens_mask']), shuffle=True, collate_fn=data_collator, batch_size=train_batch_size)\n",
    "\n",
    "# first sent nsp zero dataloader\n",
    "first_sent_nsp_zero_dataloader=DataLoader(first_sent_nsp_zero, shuffle=False, collate_fn=data_collator_embd, batch_size=eval_batch_size)\n",
    "\n",
    "# first sent nsp one  dataloader\n",
    "first_sent_nsp_one_dataloader=DataLoader(first_sent_nsp_one, shuffle=False, collate_fn=data_collator_embd, batch_size=eval_batch_size)\n",
    "\n",
    "# subset dataloader (train)\n",
    "subset_dataloader=DataLoader(subset_dataset.remove_columns(['special_tokens_mask']), shuffle=True, collate_fn=data_collator, batch_size=train_batch_size,)\n",
    "\n",
    "# eval dataloader (validation & testing)\n",
    "eval_dataloader=DataLoader(eval_dataset.remove_columns(['special_tokens_mask']), collate_fn=data_collator, batch_size=eval_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "scheduler_name = 'linear'\n",
    "num_warmup_steps = 100\n",
    "num_training_steps = 100\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# learning scheduler\n",
    "lr_scheduler = get_scheduler(\n",
    "    name=scheduler_name,\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=num_warmup_steps,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 128])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "warmer = iter(eval_dataloader)\n",
    "X= next(warmer)\n",
    "X['input_ids'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Begining warmstart\n",
      "Completed Steps: 1; Loss: 7.953183650970459; lr: [0.0];\n",
      "Completed Steps: 2; Loss: 7.613645553588867; lr: [0.0];\n",
      "Completed Steps: 3; Loss: 8.01107406616211; lr: [0.0];\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 13\u001b[0m\n\u001b[1;32m     11\u001b[0m loss \u001b[38;5;241m=\u001b[39m outputs\u001b[38;5;241m.\u001b[39mloss\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompleted Steps: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;241m1\u001b[39m\u001b[38;5;241m+\u001b[39mcompleted_steps\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m; lr: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlr_scheduler\u001b[38;5;241m.\u001b[39mget_last_lr()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     15\u001b[0m lr_scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torch/_tensor.py:522\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    513\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    514\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    515\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    520\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    521\u001b[0m     )\n\u001b[0;32m--> 522\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/torch/lib/python3.12/site-packages/torch/autograd/__init__.py:266\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    261\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    263\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    265\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 266\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    267\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "warmstart_epochs = 1\n",
    "completed_steps = 0\n",
    "\n",
    "# Warmstart the model: Train the model with the warmstart data for warmstart epochs\n",
    "for epoch in range(warmstart_epochs):\n",
    "    if epoch==0:\n",
    "        print(\"Begining warmstart\")\n",
    "    model.train() # Setup the model for training\n",
    "    for step, batch in enumerate(warmstart_dataloader):\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        print(f\"Completed Steps: {1+completed_steps}; Loss: {loss.detach().float()}; lr: {lr_scheduler.get_last_lr()};\")\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        completed_steps += 1\n",
    "        if completed_steps >= num_warmup_steps:\n",
    "            break\n",
    "\n",
    "    model.eval()\n",
    "    losses=[]\n",
    "    for step, batch in enumerate(eval_dataloader):\n",
    "        with torch.inference_mode(): # Setup the model for inference (evaluation)\n",
    "            outputs=model(**batch)\n",
    "\n",
    "        loss=outputs.loss\n",
    "        losses.append(loss)\n",
    "\n",
    "    losses=torch.cat(losses)\n",
    "    losses=losses[:len(eval_dataset)]\n",
    "    try:\n",
    "        perplexity=math.exp(torch.mean(losses))\n",
    "    except OverflowError:\n",
    "        perplexity=float(\"inf\")\n",
    "\n",
    "# Plot both training & perplexity\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_strategy = 'fl'\n",
    "# num_partitions = first_sent_nsp_one_dataloader\n",
    "# partition_strategy = None\n",
    "# submod_optimizer = 'LazyGreedy'\n",
    "\n",
    "# # Define subset selection strategies\n",
    "# if selection_strategy in ['fl', 'logdet', 'gc', 'disparity-sum']:\n",
    "#     subset_strategy = SubmodStrategy(logger, selection_strategy,\n",
    "#         num_partitions=num_partitions, partition_strategy=partition_strategy,\n",
    "#         optimizer=submod_optimizer, similarity_criterion='feature', \n",
    "#         metric='cosine', eta=1, stopIfZeroGain=False, \n",
    "#         stopIfNegativeGain=False, verbose=False, lambdaVal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection_strategy = 'fl'\n",
    "# num_samples has already been defined when creating subset.\n",
    "probs_nsp_zero=[]\n",
    "probs_nsp_one=[]\n",
    "greedyList_nsp_zero=[]\n",
    "greedyList_nsp_one=[]\n",
    "gains_nsp_zero=[]\n",
    "gains_nsp_one=[]\n",
    "\n",
    "# Begin subset selection \n",
    "if selection_strategy == 'Random-Online':\n",
    "    subset_indices_nsp_zero = [random.sample(list(range(len(first_sent_nsp_zero))), math.floor(num_samples/2))]\n",
    "    subset_indices_nsp_one = [random.sample(list(range(len(first_sent_nsp_one))), math.ceil(num_samples/2))]\n",
    "elif selection_strategy in ['fl', 'logdet', 'gc', 'disparity-sum']:\n",
    "    # Choose a selection strategy\n",
    "    model.eval() # Set the model in evaluation model \n",
    "    representations_nsp_zero=[]\n",
    "    batch_indices_nsp_zero=[]\n",
    "# Unwrap the model and set it in evaluation mode.\n",
    "\n",
    "# Go through the model specific dataset\n",
    "\n",
    "# Get the embedding and save them in a list.\n",
    "\n",
    "# Using the list and the selection strategy, get the indices and the gains of each data point in the list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put all the data into a dataset called subset_dataset\n",
    "\n",
    "# add the data to the subset dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train with importance re-sampling\n",
    "\n",
    "# Train on the entire dataset once\n",
    "\n",
    "# Sample using the indices and gains\n",
    "\n",
    "# Train the model on the sampled dataset\n",
    "\n",
    "# Evaluate the model \n",
    "\n",
    "# Save the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Personal Addition: Inference on the model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ingenious",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
